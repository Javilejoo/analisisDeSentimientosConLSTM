{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Generación de textos con Redes Neuronales\n",
    "\n",
    "En este NoteBook se creará una red que pueda generar texto.  Se verá como lo hace caracter por caracter.  En el siguiente enlace se encuentra un artículo interesante sobre esto: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "Se ha organizado el proceso en \"pasos\" para que fácilmente se pueda utilizar con cualquier conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4k0V5llBUv_"
   },
   "source": [
    "### OJO!!! Este modelo requiere una capacidad bastante alta de cómputo. De hecho no se recomienda usarlo si no se cuenta con un GPU. Recuerde que si no tiene un equipo con GPU, una alternativa conveniente es utilizar Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBd69MDEm4rF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kycWuRI9oaSP"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apj1Chkdm4rS"
   },
   "source": [
    "## Paso 1: Los Datos\n",
    "\n",
    "Se puede bajar cualquier texto en forma gratuita desde este enlace:   www.gutenberg.org/\n",
    "\n",
    "Para este ejercicio se han escogido todas las obras de Shakespeare. Esta decisión se basó en dos razones:\n",
    "\n",
    "1. Es un cuerpo enorme de texto, generalmente se recomienda que se tenga una fuente de al menos 1 millón de caracteres para lograr una generación de texto realista.\n",
    "\n",
    "2. Shakespeare tiene un estilo muy distinctivo:  uso de espacios y líneas nuevas, formato de sonetos, indicación de personajes en la obra, etc.  Como el texto está en inglés antiguo, y está formateado en el estilo de una obra de teatro, será muy fácil ver si el modelo puede producir resultados similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "direccion_archivo = 'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "texto = open(direccion_archivo, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Duhg9NrUymwO"
   },
   "outputs": [],
   "source": [
    "print(texto[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LtSyi7QBUwC"
   },
   "source": [
    "Veamos otro fragmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K91iEQ6oBUwD"
   },
   "outputs": [],
   "source": [
    "print(texto[4500:4800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSXkTGehBUwD"
   },
   "source": [
    "Y otro fragmento más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojFTS2IIBUwD"
   },
   "outputs": [],
   "source": [
    "print(texto[140500:141500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFT3mnxyBUwD"
   },
   "source": [
    "Nuestra red deberá poder detectar estas estructuras y características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXUmR627m4rd"
   },
   "source": [
    "### Ver cuáles son los caracteres únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlCgQBRVymwR"
   },
   "outputs": [],
   "source": [
    "# Los caracteres únicos en el archivo\n",
    "vocabulario = sorted(set(texto))\n",
    "print(vocabulario)\n",
    "len(vocabulario)  #importante tener este número en mente para trabajar la capa Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Paso 2: Procesamiento de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N",
    "tags": []
   },
   "source": [
    "### Vectorización de Texto\n",
    "\n",
    "Sabemos que una red neuronal no puede recibir cadenas de texto, es necesario asignar un número a cada caracter.  Se crearán dos diccionarios que puedan ir, uno de índice numérico a caracter, y el otro de caracter a índice numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDbn4CLbBUwE"
   },
   "source": [
    "Esto se puede hacer bastante fácil si usamos la función enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPaGxEw2BUwF"
   },
   "outputs": [],
   "source": [
    "for tupla in enumerate(vocabulario):\n",
    "    print(tupla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjcwwYccBUwF"
   },
   "source": [
    "Usando esto, ahora vamos a crear un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "caract_a_indice = {u:i for i, u in enumerate(vocabulario)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmmP5iCwm4rp"
   },
   "outputs": [],
   "source": [
    "caract_a_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30ZYaWAOm4rt"
   },
   "outputs": [],
   "source": [
    "indice_a_caract = np.array(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6JPOWwJm4rz"
   },
   "outputs": [],
   "source": [
    "indice_a_caract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_wB4HOzBUwG"
   },
   "source": [
    "Con esto fácilmente podemos ir de un caracter a su código y viceversa...por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYgpVo0bBUwG"
   },
   "outputs": [],
   "source": [
    "caract_a_indice[\"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3H3oJKVDBUwG"
   },
   "outputs": [],
   "source": [
    "indice_a_caract[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fhOqV0lm4r2"
   },
   "outputs": [],
   "source": [
    "texto_codificado = np.array([caract_a_indice[c] for c in texto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axOX7rFom4r5"
   },
   "outputs": [],
   "source": [
    "texto_codificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX",
    "tags": []
   },
   "source": [
    "Ahora tenemos un mapeo que nos permite ir de caracteres a numérico y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFs1Uza-m4r9"
   },
   "outputs": [],
   "source": [
    "muestra = texto[:500]\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIqUCK5Am4sB"
   },
   "outputs": [],
   "source": [
    "texto_codificado[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cuántos caracteres tiene todo el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_codificado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay aproximadamente 5.5 millones de caracteres...más que suficiente para nuestros propósitos\n",
    "\n",
    "Podemos ver cómo se ve el texto normal y en forma codificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto[: 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_codificado[: 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe",
    "tags": []
   },
   "source": [
    "## Paso 3: Crear Tandas\n",
    "\n",
    "Haremos tres cosas:\n",
    "\n",
    "* Entender qué son las secuencias de texto\n",
    "* Utilizar la clase \"datasets\" que tiene TensorFlow para generar las tandas\n",
    "* \"Barajear\" las tandas\n",
    "\n",
    "En general, lo que se trata de hacer es lograr que el modelo prediga el siguiente caracter con una alta probabilidad, dada una secuencia histórica de caracteres.  \n",
    "\n",
    "El usuario debe decidir qué tan larga va a ser esa secuencia histórica.  Debe tomarse en cuenta que si se usa una secuencia muy corta, no se tiene suficiente información (e.g. dados la letra \"a\", cuál es el siguiente caracter).  En el otro extremo, si se usa una secuencia muy larga, el entrenamiento será muy largo y lo más probable es que haya un *sobre ajuste* a caracteres secuenciales que son irrelevantes a caracteres más lejanos.\n",
    "\n",
    "Si bien no hay una selección de longitud de secuencia correcta, es importante considerar al texto mismo, qué tan largas son las frases normales que tiene, y una idea razonable sobre qué caracteres/palabras son relevantes entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAvUYFk7m4sF"
   },
   "outputs": [],
   "source": [
    "print(texto[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D45OYgOfm4sJ"
   },
   "outputs": [],
   "source": [
    "linea = \"From fairest creatures we desire increase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dKiEVN8m4sL"
   },
   "outputs": [],
   "source": [
    "len(linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olX67f6-m4sP"
   },
   "outputs": [],
   "source": [
    "parte_estrofa = \"\"\"From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qal7MQnqm4sQ"
   },
   "outputs": [],
   "source": [
    "len(parte_estrofa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Secuencias de entrenamiento\n",
    "\n",
    "El texto actual será la secuencia de texto desplazado hacia adelante en un caracter. Por ejemplo:\n",
    "\n",
    "\n",
    "Secuencia Entrante: \"Hola mi nom\"\n",
    "\n",
    "Secuencia Saliente: \"ola mi nomb\"\n",
    "\n",
    "\n",
    "Se puede usar la clase `tf.data.Dataset.from_tensor_slices` para  convertir un vector de texto a un flujo de indices de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "# Viendo que una línea es de aprox 40 caracteres y que Shakespeare\n",
    "#   utiliza una rima, mas o menos, a cada 3 líneas, seleccionamos:\n",
    "\n",
    "long_secuencia = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VRSK4cOm4sZ"
   },
   "outputs": [],
   "source": [
    "num_total_secuencias = len(texto)//(long_secuencia + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtW0jbbvm4sc"
   },
   "outputs": [],
   "source": [
    "num_total_secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciatnowvm4se"
   },
   "outputs": [],
   "source": [
    "# Crear las secuencias de entrenamiento\n",
    "conjunto_caract = tf.data.Dataset.from_tensor_slices(texto_codificado)\n",
    "type(conjunto_caract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpJv_ubhBUwJ"
   },
   "source": [
    "Como siempre, para ver qué métodos hay disponibles para este tipo de datos, podemos escribir:\n",
    "\n",
    "**conjunto_caract.** y luego dar un \"tab\"\n",
    "\n",
    "usaremos el método **batch()**\n",
    "\n",
    "Para ver cómo funciona, lo probaremos con una porción del texto total.  Para esto podemos usar el método **take()**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUoi5zAQzdnF"
   },
   "outputs": [],
   "source": [
    "for i in conjunto_caract.take(500):        # Toma un grupo de a lo sumo 500 elementos\n",
    "     print(indice_a_caract[i.numpy()])     # Parar poder imprimirlos, hay que convertirlos a numpy y convertir a caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "El método de tandas **batch()** convierte los elementos individuales a secuencias que se pueden alimentar en tandas.  Le pasamos long_secuencia + 1 (debido a que la indización empieza en cero).  \n",
    "\n",
    "Otro parámetro que tiene el método **batch()** es *drop_remainder*.  Este es un parámetro opcional, y es un escalar `tf.Tensor` de tipo `tf.bool`, que indica si la última secuencia debe ser \"botada\" en caso tenga menos de long_secuencia elementos. El valor default es 'False' o sea no botar la tanda menor.\n",
    "\n",
    "Como nuestra secuencias son de 120 caracteres, es posible que en cada tanda quede un residuo de entre 1 y 119 caracteres.  Comparado a los casi 5 millones de caracteres de nuestro texto completo, esto es insignificante por lo que vamos a decirle que bote los residuos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [],
   "source": [
    "secuencias = conjunto_caract.batch(long_secuencia + 1,\n",
    "                                   drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "Ahora que ya se tienen las secuencias, se ejecutarán los siguientes pasos para crear las secuencias de texto meta:\n",
    "\n",
    "1. Obtener la secuencia de texto entrante\n",
    "2. Asignar la secuencia de texto meta como la secuencia de texto entrante, desplazada por un paso hacia adelante\n",
    "3. Agruparlos como una tupla (secuencia_entrante, secuencia_saliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def crear_secuencias_meta(sec):\n",
    "    texto_entrada = sec[:-1]      # Algo como \"Hola mi nombr\"\n",
    "    texto_meta = sec[1:]          # Algo como \"ola mi nombre\"\n",
    "    return texto_entrada, texto_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HszljTg8m4so"
   },
   "outputs": [],
   "source": [
    "# El conjunto de datos final que se alimentará a la red\n",
    "datos = secuencias.map(crear_secuencias_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ3-XsE4BUwK"
   },
   "source": [
    "Veamos el ejemplo de una secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkPa7AMrm4sq"
   },
   "outputs": [],
   "source": [
    "for texto_entrada, texto_meta in datos.take(1):\n",
    "    print(texto_entrada.numpy())\n",
    "    print(''.join(indice_a_caract[texto_entrada.numpy()]))\n",
    "    print('\\n')\n",
    "    print(texto_meta.numpy())\n",
    "    # Hay espacio en blanco extra!\n",
    "    print(''.join(indice_a_caract[texto_meta.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Generar las tandas de entrenamiento\n",
    "\n",
    "Ahora que se tienen las secuencias, se crearán las tandas.  Se \"barajean\" estas secuencias en un orden al azar, para que el modelo no se sobreajuste a cualquier sección de texto, pero que pueda generar caracteres dados cualquier texto \"semilla\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "tamanio_tanda = 128     # Cuántas secuencias habrán en cada tanda...mejor si es múltiplo de dos\n",
    "\n",
    "# Tamaño del espacio \"Buffer\" para barajear los datos con el fin\n",
    "#   de que no intente barajear toda la secuencie en memoria.  En\n",
    "#   vez, mantiene un  \"buffer\" en el cual barajea elementos\n",
    "\n",
    "tamanio_buffer = 10000         # Este dependerá de cuánta memoria se tiene en el computador\n",
    "\n",
    "datos = datos.shuffle(tamanio_buffer).batch(tamanio_tanda,\n",
    "                                            drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmcCALymm4su"
   },
   "outputs": [],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar la forma, tenemos una tupla (la de entrada) de 128 secuencas de 120 caracteres, y otra que tupla (la de salida, **o meta**) de iguales dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Paso 4: Crear el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "Se usará un modelo originalmente basado en LSTM con unas características extra, incluyendo una capa de incrustación \"embedding\" para empezar, y **dos** capas LSTM. Esta arquitectura de modelo se basa en [DeepMoji](https://deepmoji.mit.edu/) y la fuente original del código puede ser encontrada [aquí](https://github.com/bfelbo/DeepMoji).\n",
    "\n",
    "Se puede utilizar cualquier combinación de capas pero este ejercio se hará con el modelo más simple que permita mostrar resultados \"realistas\".  En vez de las capas LSTM se usará una de GRU.\n",
    "\n",
    "La capa de incrustación servirá como la capa de entrada.  Esencialmente, esta crea una tabla de consulta que mapea los índices numéricos de cada caracter a un vector con \"dim_incrust\" número de dimensiones.  Como es de imaginar, entre más grande este tamaño de incrustación, más complejo el entrenamiento. Hacer la incrustación antes de alimentar directamente al GRU, generalmente conlleva a resultados mas realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitud del vocabulario de caracteres\n",
    "\n",
    "long_vocab = len(vocabulario)\n",
    "long_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dimensionamiento de la incrustación.  Se trata de que sea de\n",
    "#    orden aproximado a long_vocab.  No es deseable que sea mucho\n",
    "#    más grande ya que el incremento en dimensiones afecta el\n",
    "#    tiempo de ejecución\n",
    "\n",
    "dim_incrust = 64\n",
    "\n",
    "# Número de unidades RNN\n",
    "\n",
    "neuronas_rnn = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Atb060h5m4s0"
   },
   "source": [
    "Ahora se creará una función que se adapte fácilmente a variables diferentes como se ha mostrado arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeRlEXgym4s1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# se puede \"jugar\" con todo tipo de capas\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU\n",
    "\n",
    "# para este ejemplo solo usaremos Dense, Embedding, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcMbIy-xj-w-"
   },
   "source": [
    "### Configurar la función de pérdida\n",
    "\n",
    "Para la pérdida se utilizará *sparse categorical crossentropy*, que se puede importar de Keras.  Se selecciona esta debido a que las etiquetas están \"one hot encoded\"\n",
    "\n",
    "También se dejará  **from_logits = True**, ya que este parámetro se refiere a si las etiquetas están, o no, \"one hot encoded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoFVGKlNkJfW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sblCzZoslZKH"
   },
   "outputs": [],
   "source": [
    "help(sparse_categorical_crossentropy)   # para mayor información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5N4Qxbij5gY"
   },
   "source": [
    "https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx8UumGZBUwM"
   },
   "source": [
    "Más abajo, al compilar el modelo, cuando indiquémos qué función de pérdida se desea usar, solo nos permite dar el nombre de la función, no nos permite pasar parámetros.  \n",
    "\n",
    "Debido a que \"sparse_categorical_crossentropy\" tiene por default **from_logits = False**, se necesita una forma de cambiarlo.  Esto se hace envolviendo o poniendo un \"wrapper\" al método.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrOOK61Olm1C"
   },
   "outputs": [],
   "source": [
    "def perdida_categ_escasa(y_real,y_pred):\n",
    "  return sparse_categorical_crossentropy(y_real, y_pred,\n",
    "                                         from_logits = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtglvynNBUwN"
   },
   "source": [
    "Definimos una función para crear el modelo de tal forma que, cuando se quiera probar con otros cojuntos de texto, será más fácil cambiar los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def crear_modelo(tamanio_vocab, dim_incrust, neuronas_rnn,\n",
    "                 tamanio_tanda):\n",
    "\n",
    "    modelo = Sequential()\n",
    "    \n",
    "#    modelo.add(Embedding(tamanio_vocab, dim_incrust,                   #Versiones anteriores e Tensorflow\n",
    "#                         batch_input_shape = [tamanio_tanda, None]))\n",
    "    \n",
    "    modelo.add(Embedding(input_dim = long_vocab,  # tamaño del vocabulario\n",
    "                         output_dim = dim_incrust,  # dimensión de incrustación\n",
    "                         input_length = None))  # usar None si la longitud de la secuencia es variable\n",
    "    \n",
    "    modelo.add(GRU(neuronas_rnn, return_sequences = True,\n",
    "                   stateful = True,\n",
    "                   recurrent_initializer = 'glorot_uniform'))\n",
    "\n",
    "    # Capa Final Densa para Predecir\n",
    "    modelo.add(Dense(long_vocab))\n",
    "\n",
    "    modelo.compile(optimizer = 'adam', loss = perdida_categ_escasa)\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "modelo = crear_modelo(long_vocab, dim_incrust,\n",
    "                      neuronas_rnn, tamanio_tanda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liXuTFYMm4s6"
   },
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Paso 5: Entrenar el modelo\n",
    "\n",
    "Antes de perder mucho tiempo con el modelo, se verifica que todo funcione bien.  Se le alimentará una tanda para asegurar que el modelo predice caracteres al azar, sin entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ygvfHn-wan"
   },
   "outputs": [],
   "source": [
    "for tanda_muestra_entrada, tanda_muestra_meta in datos.take(1):\n",
    "\n",
    "  # Prededir a partir de una tanda al azar\n",
    "  tanda_muestra_predicciones = modelo(tanda_muestra_entrada)\n",
    "\n",
    "  # Desplegar las dimensiones de las predicciones\n",
    "  print(tanda_muestra_predicciones.shape,\n",
    "        \" <=== (tamanio_tanda, long_secuencia, long_vocab)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ld8z3LPBAuv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tanda_muestra_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c_HLMh8BUwO"
   },
   "source": [
    "Este es un montón de probabilidades logaritmicas que asume para cada caracter concurrente, necesitamos algo que nos facilite ver estos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_achqjT-BGyY"
   },
   "outputs": [],
   "source": [
    "indices_muestreados = tf.random.categorical(tanda_muestra_predicciones[0],\n",
    "                                            num_samples = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWrPFk2nBJX4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices_muestreados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEjJDhrqBUwO"
   },
   "source": [
    "Reformatear para que no sea una lista de listas, sino que quede en el formato que deseamos para pasarlo a nuestra función de conversión a caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wi80PQVtBLqj"
   },
   "outputs": [],
   "source": [
    "\n",
    "indices_muestreados = tf.squeeze(indices_muestreados,\n",
    "                                 axis = -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qYkIg00-wjq"
   },
   "outputs": [],
   "source": [
    "indices_muestreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9-P_XqQ_7wY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Dado la secuencia de entrada: \\n\")\n",
    "print(\"\".join(indice_a_caract[tanda_muestra_entrada[0]]))\n",
    "print('\\n')\n",
    "print(\"Predicciones del siguiente caracter: \\n\")\n",
    "print(\"\".join(indice_a_caract[indices_muestreados ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAOE4rzuBh7f"
   },
   "source": [
    "Lo que vemos es un montón de caracteres al azar, porque el modelo aún no ha sido entrenado.\n",
    "\n",
    "Luego de confirmar las dimensiones, se procede a entrenar la red!\n",
    "\n",
    "**NOTA:**\n",
    "\n",
    "Este paso puede ser bastante tardado, aún con Google Colab.  Asumiendo que se ha guardado el modelo después de haberlo entrenado, se pueden  saltear las siguientres tres celdas de código y continuar con la siguiente celda.  Esta asume que el modelo entrenado se ha guardado en *shakespeare_gen.h5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYDQjKTlm4s8"
   },
   "outputs": [],
   "source": [
    "epocas = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PJ4OVdBm4s8"
   },
   "outputs": [],
   "source": [
    "modelo.fit(datos, epochs = epocas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Paso 6: Generar texto\n",
    "\n",
    "Como está ahorita, el modelo espera 128 secuencias a la vez.  Se puede crear un modelo que espere un tamanio_tanda = 1, y luego cargar los pesos que se han guardado.  Luego se invoca *.build()* sobre el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYRNG57Govdc"
   },
   "outputs": [],
   "source": [
    "#modelo.save('shakespeare_gen.h5')\n",
    "modelo.save('shakespeare.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCoJayFS8H4d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iXG3VJvEXWM"
   },
   "outputs": [],
   "source": [
    "modelo = crear_modelo(long_vocab, dim_incrust,\n",
    "                      neuronas_rnn, tamanio_tanda = 1)\n",
    "\n",
    "modelo.build(tf.TensorShape([1, None]))\n",
    "\n",
    "#modelo.load_weights('shakespeare_gen.h5')  # Versiones anteriores de Tensorflow\n",
    "modelo.load_weights('shakespeare.keras')\n",
    "\n",
    "#modelo.build(tf.TensorShape([1, None]))  # Con versiones anteriores de Tensorflow había que poner esta instrucción aqí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAX3p7_YEilU"
   },
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvuwZBX5Ogfd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generar_texto(modelo, semilla_inicial, num_caract = 500, temp = 1.0):\n",
    "  '''\n",
    "  modelo: Modelo entrenado para Generar Texto\n",
    "\n",
    "  semilla_inicial: Texto en formato cadena \"string\" a usar como semilla\n",
    "  num_caract: Número de caracteres a generar\n",
    "\n",
    "  La idea básica de esta función es la de tomar un texto semilla,\n",
    "  formatearlo para que quede en la forma correcta para nuestra red,\n",
    "  luego pasar la secuencia por una iteración conforme se le vayan\n",
    "  agregando los caracteres predichos.  Parecido a lo que se hace\n",
    "  con RNNs y series de tiempo.\n",
    "  '''\n",
    "\n",
    "  # Número de caracteres a generar\n",
    "  num_generar = num_caract\n",
    "\n",
    "  # Vectorización del texto semilla\n",
    "  eval_entrada = [caract_a_indice[s] for s in semilla_inicial]\n",
    "\n",
    "  # Expandir para llegar al formato requerido de tanda\n",
    "  eval_entrada = tf.expand_dims(eval_entrada, 0)\n",
    "\n",
    "  # Lista vacía para acumular el texto generado\n",
    "  texto_generado = []\n",
    "\n",
    "  # La \"temperatura\" afecta la aleatoriedad en el texto resultante\n",
    "  # El término es derivado de entropía/termodinámica.\n",
    "  # La \"temperatura\" se utiliza para afectar la probabilidad de\n",
    "  #    los siguientes caracteres.\n",
    "  # Temperatura mayor == menos sorprendente/ más esperado\n",
    "  # Temperatura menor == más sorprendente / menos esperado\n",
    "\n",
    "  temperatura = temp\n",
    "\n",
    "  # Recordar que aquí tamanio_tanda == 1\n",
    "  modelo.reset_states()\n",
    "\n",
    "  for i in range(num_generar):\n",
    "\n",
    "      # Generar Predicciones\n",
    "      predicciones = modelo(eval_entrada)\n",
    "\n",
    "      # Eliminar la dimensión de la forma de las tandas\n",
    "      predicciones = tf.squeeze(predicciones, 0)\n",
    "\n",
    "      # Usar una distribución categórica para escoger el\n",
    "      #   siguiente caracter\n",
    "      predicciones = predicciones / temperatura\n",
    "      id_predicho = tf.random.categorical(predicciones,\n",
    "                                          num_samples = 1)[-1,0].numpy()\n",
    "\n",
    "      # Pasar el caracter predicho para la siguiente entrada\n",
    "      eval_entrada = tf.expand_dims([id_predicho], 0)\n",
    "\n",
    "      # Transformar de vuelta a una letra\n",
    "      texto_generado.append(indice_a_caract[id_predicho])\n",
    "\n",
    "  return (semilla_inicial + ''.join(texto_generado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_texto(modelo, semilla_inicial, num_caract=500, temp=1.0):\n",
    "    '''\n",
    "    modelo: Modelo entrenado para Generar Texto\n",
    "    semilla_inicial: Texto en formato cadena \"string\" a usar como semilla\n",
    "    num_caract: Número de caracteres a generar\n",
    "    temp: Temperatura para controlar la aleatoriedad del texto generado\n",
    "    \n",
    "    La idea básica de esta función es la de tomar un texto semilla,\n",
    "    formatearlo para que quede en la forma correcta para nuestra red,\n",
    "    luego pasar la secuencia por una iteración conforme se le vayan\n",
    "    agregando los caracteres predichos.  Parecido a lo que se hace\n",
    "    con RNNs y series de tiempo.\n",
    "    '''\n",
    "\n",
    "    # Número de caracteres a generar\n",
    "    num_generar = num_caract\n",
    "\n",
    "    # Vectorización del texto semilla\n",
    "    eval_entrada = [caract_a_indice[s] for s in semilla_inicial]\n",
    "\n",
    "    # Expandir para llegar al formato requerido de tanda\n",
    "    eval_entrada = tf.expand_dims(eval_entrada, 0)\n",
    "\n",
    "    # Lista vacía para acumular el texto generado\n",
    "    texto_generado = []\n",
    "\n",
    "    # La \"temperatura\" afecta la aleatoriedad en el texto resultante\n",
    "    temperatura = temp\n",
    "\n",
    "    # Removemos la línea modelo.reset_states() ya que Sequential no tiene este método\n",
    "    # Si necesitas reiniciar estados, considera usar un enfoque diferente o un modelo personalizado\n",
    "\n",
    "    for i in range(num_generar):\n",
    "        # Generar Predicciones\n",
    "        predicciones = modelo(eval_entrada)\n",
    "\n",
    "        # Eliminar la dimensión de la forma de las tandas\n",
    "        predicciones = tf.squeeze(predicciones, 0)\n",
    "\n",
    "        # Usar una distribución categórica para escoger el siguiente caracter\n",
    "        predicciones = predicciones / temperatura\n",
    "        id_predicho = tf.random.categorical(predicciones,\n",
    "                                          num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pasar el caracter predicho para la siguiente entrada\n",
    "        eval_entrada = tf.expand_dims([id_predicho], 0)\n",
    "\n",
    "        # Transformar de vuelta a una letra\n",
    "        texto_generado.append(indice_a_caract[id_predicho])\n",
    "\n",
    "    return (semilla_inicial + ''.join(texto_generado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS69SG5D5lwd"
   },
   "outputs": [],
   "source": [
    "print(generar_texto(modelo, \"flower\", num_caract = 1000))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf-metal)",
   "language": "python",
   "name": "tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
